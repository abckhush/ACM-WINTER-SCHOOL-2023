{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### FAQs for the Image + Tweets Code:\n",
        "\n",
        "**1. What is the purpose of the code block with `drive.mount('/content/drive')`?**\n",
        "   - This line mounts Google Drive to the Colab environment, allowing access to files and folders stored in Google Drive.\n",
        "\n",
        "**2. How is the CSV file loaded, and what is its path?**\n",
        "   - The CSV file is loaded using the `read_csv` function from the pandas library. The path to the CSV file is specified by combining the folder path and the file name (`'text_image_features.csv'`).\n",
        "\n",
        "**3. What does the line `data_all.columns = range(data_all.shape[1])` do?**\n",
        "   - This line sets the column names of the DataFrame (`data_all`) to a range of integers from 0 to the number of columns in the DataFrame. It is likely used to reindex the columns.\n",
        "\n",
        "**4. How are the dataframes `data_all` and `data_testing` used, and why is `data_testing` commented out?**\n",
        "   - `data_all` is used to read and display the content of the CSV file. However, `data_testing` is loaded but commented out, meaning it is not used in the current code snippet.\n",
        "\n",
        "**5. Why is there a commented-out block (`# print(data_all)`) at the end of the code?**\n",
        "   - This block is commented out, so it doesn't have any effect on the program. If uncommented, it would print the content of the `data_all` DataFrame.\n",
        "\n",
        "**6. What information does the printed DataFrame (`data_all`) provide?**\n",
        "   - The printed DataFrame likely shows the contents of the CSV file loaded into `data_all`. Each row represents an entry, and columns represent different features or attributes of the data.\n",
        "\n",
        "**7. How can I access specific rows or columns in the DataFrame?**\n",
        "   - You can use DataFrame indexing and slicing. For example, `data_all.iloc[0]` would give you the first row, and `data_all['column_name']` would give you the entire column with the specified name.\n",
        "\n",
        "**8. What should I do if I want to perform specific operations on the loaded data?**\n",
        "   - Depending on your tasks, you can manipulate the data using pandas DataFrame methods. For example, filtering rows based on conditions, selecting specific columns, or merging multiple DataFrames.\n",
        "\n",
        "**9. Why is the header commented out in the line `# data_all = data_all_with_header[1:]`?**\n",
        "   - If there's an issue with the header or if the first row contains data and not header information, uncommenting this line could be an attempt to skip the first row, treating it as data rather than header.\n",
        "\n",
        "**10. How can I save the modified DataFrame back to a CSV file?**\n",
        "   - You can use the `to_csv` method provided by pandas. For example, `data_all.to_csv('/path/to/save/folder/new_file.csv', index=False)` would save the DataFrame to a new CSV file without the index column."
      ],
      "metadata": {
        "id": "iHFYEXVfamfi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FjfxvLdHfIH",
        "outputId": "96c10214-b197-4dc7-9e4c-fc0dd7f19f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "      0                   1             2     3         4         5     \\\n",
            "0        0  553477352542707712  charliehebdo     0  0.636200 -0.431506   \n",
            "1        1  553589285342175232  charliehebdo     0  0.621822 -0.445261   \n",
            "2        2  552810804186460161  charliehebdo     0  0.631295 -0.414676   \n",
            "3        3  553535971959275520  charliehebdo     0  0.579590 -0.487810   \n",
            "4        4  553579224402235393  charliehebdo     0  0.634513 -0.398629   \n",
            "...    ...                 ...           ...   ...       ...       ...   \n",
            "5797  5797  544419008615702528   sydneysiege     1  0.623159 -0.450512   \n",
            "5798  5798  544458558432350208   sydneysiege     1  0.643508 -0.393522   \n",
            "5799  5799  544408293192368128   sydneysiege     1  0.620613 -0.406470   \n",
            "5800  5800  544395804190855168   sydneysiege     1  0.596901 -0.408938   \n",
            "5801  5801  544453251068743681   sydneysiege     1  0.603882 -0.449194   \n",
            "\n",
            "          6         7         8         9     ...      2042      2043  \\\n",
            "0    -0.349595  0.483405  0.905400 -0.031609  ...  0.336440  0.468022   \n",
            "1    -0.342131  0.468382  0.903240 -0.025753  ...  0.166437 -0.044542   \n",
            "2    -0.335901  0.459042  0.904806  0.026553  ... -0.239752 -0.009435   \n",
            "3    -0.472168  0.562279  0.898860 -0.033659  ... -0.306577 -0.010337   \n",
            "4    -0.282867  0.467576  0.905472 -0.010305  ... -0.026789  0.071898   \n",
            "...        ...       ...       ...       ...  ...       ...       ...   \n",
            "5797 -0.343630  0.447833  0.903683 -0.008353  ... -0.239346 -0.334968   \n",
            "5798 -0.360706  0.469223  0.901632  0.009424  ...  0.457082 -0.242168   \n",
            "5799 -0.350437  0.458320  0.903481 -0.023498  ... -0.346550  0.186374   \n",
            "5800 -0.294388  0.470328  0.907058  0.007090  ...  0.612451  0.078028   \n",
            "5801 -0.432768  0.542725  0.896634 -0.098681  ... -0.551057 -0.158098   \n",
            "\n",
            "          2044      2045      2046      2047      2048      2049      2050  \\\n",
            "0    -0.157085  0.324943  0.414457 -0.095692 -0.155969  0.483707 -0.420402   \n",
            "1    -0.050826  0.018506  0.114480  0.456421  0.355459  0.326754 -0.174336   \n",
            "2    -0.644391 -0.141651 -0.003093  0.037951  0.039547  0.432339  0.005572   \n",
            "3    -0.351043  0.038229  0.132781  0.413877  0.315803 -0.308119  0.079741   \n",
            "4    -0.072227 -0.112164  0.068634  0.287598 -0.228631  0.145636 -0.131200   \n",
            "...        ...       ...       ...       ...       ...       ...       ...   \n",
            "5797 -0.151896  0.257407 -0.023585  0.181173 -0.594253  0.109422 -0.149029   \n",
            "5798  0.905843 -0.689110  0.385119 -0.062982 -0.154464  0.974708  0.709871   \n",
            "5799  1.140451 -0.270451 -0.026243 -0.358442 -0.002504 -0.129577 -0.234409   \n",
            "5800  0.281774  0.079215 -0.311721 -0.487753 -0.042243 -0.144389  0.073968   \n",
            "5801  0.914955 -0.288188 -0.478286  1.016367 -0.431967  0.504365 -0.590097   \n",
            "\n",
            "          2051  \n",
            "0    -0.525067  \n",
            "1     0.114290  \n",
            "2    -0.421931  \n",
            "3    -0.070107  \n",
            "4    -0.110499  \n",
            "...        ...  \n",
            "5797 -0.117964  \n",
            "5798 -0.825301  \n",
            "5799 -0.554593  \n",
            "5800 -0.028642  \n",
            "5801 -0.618770  \n",
            "\n",
            "[5802 rows x 2052 columns]\n"
          ]
        }
      ],
      "source": [
        "# FOR IMAGE + TWEETS\n",
        "\n",
        "import os\n",
        "from pandas import *\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the folder containing your CSV file\n",
        "folder_path = '/content/drive/MyDrive/fake-news-hands-on/'\n",
        "\n",
        "# Path to the CSV file\n",
        "csv_file_path = folder_path + 'text_image_features.csv'\n",
        "\n",
        "\n",
        "path_to_data = csv_file_path\n",
        "# path_to_testing_data = \"testing_data.csv\"\n",
        "\n",
        "data_all = read_csv('/content/drive/MyDrive/fake-news-hands-on/text_image_features.csv')\n",
        "# data_testing = read_csv(path_to_testing_data, header = None)\n",
        "\n",
        "data_all.columns = range(data_all.shape[1])\n",
        "\n",
        "\n",
        "print(data_all)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FAQs for Data Shuffling and Splitting:\n",
        "\n",
        "**1. What is the purpose of the code block with `data_all.sample(frac=1, random_state=47).values`?**\n",
        "   - This code shuffles the rows of the DataFrame (`data_all`) randomly. The `frac=1` parameter ensures that the entire DataFrame is shuffled, and `random_state=47` provides reproducibility by setting the random seed.\n",
        "\n",
        "**2. How is the shuffling done, and why is it important?**\n",
        "   - The shuffling is achieved using the `sample` method, which randomly samples rows from the DataFrame. Shuffling is crucial to ensure that the data is randomized before splitting it into training and testing sets.\n",
        "\n",
        "**3. What does `Y_train = data_all.loc[0:1024,3]` do?**\n",
        "   - This line extracts the target variable (Y) for the training set. It assumes that the target variable is located in the fourth column (index 3) of the DataFrame and selects rows from 0 to 1024 (inclusive).\n",
        "\n",
        "**4. What does `X_train = data_all.loc[0:1024,4:2051]` do?**\n",
        "   - This line extracts the features (X) for the training set. It assumes that the features are located in columns 4 to 2051 of the DataFrame and selects rows from 0 to 1024 (inclusive).\n",
        "\n",
        "**5. How are the training and testing sets split using `loc`?**\n",
        "   - The training set (`Y_train` and `X_train`) is selected from rows 0 to 1024, while the testing set (`Y_test` and `X_test`) is selected from rows 1024 to 1048.\n",
        "\n",
        "**6. What does `# print(data_all.shape)` signify?**\n",
        "   - The commented-out line would print the shape of the DataFrame (`data_all`). It provides information about the number of rows and columns in the DataFrame.\n",
        "\n",
        "**7. How can I print the contents of the training and testing sets (`X_train`, `Y_train`, `X_test`, `Y_test`)?**\n",
        "   - Uncommenting the lines `# print(X_train)` and `# print(Y_train)` would print the contents of the training set features and target variable, respectively. Similar lines can be added for the testing set.\n",
        "\n",
        "**8. What is the purpose of shuffling and splitting the data into training and testing sets?**\n",
        "   - Shuffling ensures that the model is exposed to a diverse set of examples during training, and splitting into training and testing sets allows for evaluating the model's performance on unseen data.\n",
        "\n",
        "**9. How can I modify the code to use a different percentage for training and testing sets?**\n",
        "   - You can adjust the row indices in the `loc` functions. For example, changing `loc[0:1024]` to `loc[0:800]` would result in a larger training set and a smaller testing set.\n",
        "\n",
        "**10. What should I do if I want to use a different random seed for shuffling?**\n",
        "   - Change the `random_state` parameter to a different integer in both the shuffling and splitting lines. Using a seed helps in reproducibility."
      ],
      "metadata": {
        "id": "ARl0Eqfvbf5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle the DataFrame rows of training data\n",
        "data_all[:] = data_all.sample(frac = 1, random_state = 47).values\n",
        "# print(data_all.shape)\n",
        "\n",
        "Y_train = data_all.loc[0:128,3]\n",
        "\n",
        "X_train = data_all.loc[0:128,4:2051]\n",
        "\n",
        "\n",
        "Y_test = data_all.loc[1024:1048,3]\n",
        "\n",
        "X_test = data_all.loc[1024:1048,4:2051]\n"
      ],
      "metadata": {
        "id": "xttmeuelJ5Zx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FAQs for Classifier Training and Evaluation:\n",
        "\n",
        "**1. What is the purpose of this code block?**\n",
        "   - This code block trains multiple classifiers on the given training data and evaluates their performance on the test data. It includes various classifiers such as Logistic Regression, SVM, Decision Tree, Random Forest, etc.\n",
        "\n",
        "**2. How are the classifiers specified, and why are they included in a dictionary (`dict_classifiers`)?**\n",
        "   - Classifiers are specified with their names and corresponding instances in the `dict_classifiers` dictionary. This allows for easy iteration over different classifiers and simplifies the training and evaluation process.\n",
        "\n",
        "**3. What functions are used for data preprocessing and feature selection?**\n",
        "   - The code snippet does not explicitly include data preprocessing or feature selection. However, common preprocessing techniques like scaling and encoding may be applied before passing data to classifiers.\n",
        "\n",
        "**4. How is the training and evaluation process done for multiple classifiers?**\n",
        "   - The `batch_classify` function iterates over the specified number of classifiers, fits each classifier on the training data, and evaluates its performance on the test data. The results are stored in a dictionary (`dict_models`).\n",
        "\n",
        "**5. What metrics are used to evaluate classifier performance?**\n",
        "   - The code computes and prints various metrics for each classifier, including training and test scores, training time, precision, recall, F1-score, and class-specific accuracies (acc1 and acc2).\n",
        "\n",
        "**6. How can I control the number of classifiers used for training?**\n",
        "   - The `no_classifiers` parameter in the `batch_classify` function determines the number of classifiers to train and evaluate. You can adjust this parameter based on your preference.\n",
        "\n",
        "**7. What does `display_dict_models` do, and how is the output sorted?**\n",
        "   - `display_dict_models` creates a DataFrame from the results stored in `dict_models` and displays it. The output is sorted based on the specified metric in the `sort_by` parameter (default is 'test_score').\n",
        "\n",
        "**8. Can I add or remove classifiers from the training process?**\n",
        "   - Yes, you can modify the `dict_classifiers` dictionary to include or exclude classifiers based on your preferences. Ensure that the dictionary keys match the names of the classifiers in scikit-learn.\n",
        "\n",
        "**9. How can I interpret the output DataFrame from `display_dict_models`?**\n",
        "   - The DataFrame provides a summary of the performance metrics for each classifier. It includes columns for classifier name, training and test scores, training time, precision, recall, F1-score, and class-specific accuracies.\n",
        "\n",
        "**10. Is there a specific reason for using specific classifiers in this example?**\n",
        "   - The choice of classifiers in `dict_classifiers` is arbitrary and depends on the problem at hand. It's common to include a mix of linear and non-linear classifiers to see how they perform on the given dataset. You can experiment with different classifiers based on your requirements."
      ],
      "metadata": {
        "id": "YTUwXdQibwgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "dict_classifiers = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
        "    \"Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Rbf SVM\": SVC(kernel='rbf',gamma=0.45, C=3.7),\n",
        "    \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=1000),\n",
        "    \"Neural Net\": MLPClassifier(alpha = 1),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(n_estimators=1000),\n",
        "    \"QDA\": QuadraticDiscriminantAnalysis(),\n",
        "}\n",
        "\n",
        "def batch_classify(X_train, Y_train, X_test, Y_test, no_classifiers = 5, verbose = True):\n",
        "    \"\"\"\n",
        "    This method, takes as input the X, Y matrices of the Train and Test set.\n",
        "    And fits them on all of the Classifiers specified in the dict_classifier.\n",
        "    The trained models, and accuracies are saved in a dictionary. The reason to use a dictionary\n",
        "    is because it is very easy to save the whole dictionary with the pickle module.\n",
        "\n",
        "    Usually, the SVM, Random Forest and Gradient Boosting Classifier take quiet some time to train.\n",
        "    So it is best to train them on a smaller dataset first and\n",
        "    decide whether you want to comment them out or not based on the test accuracy score.\n",
        "    \"\"\"\n",
        "\n",
        "    dict_models = {}\n",
        "    for classifier_name, classifier in list(dict_classifiers.items())[:no_classifiers]:\n",
        "        t_start = time.process_time()\n",
        "        classifier.fit(X_train, Y_train)\n",
        "        t_end = time.process_time()\n",
        "\n",
        "        t_diff = t_end - t_start\n",
        "        train_score = classifier.score(X_train, Y_train)\n",
        "        test_score = classifier.score(X_test, Y_test)\n",
        "\n",
        "        y_pred = classifier.predict(X_test)\n",
        "        precision_value = metrics.precision_score(Y_test, y_pred)\n",
        "        recall_value = metrics.recall_score(Y_test, y_pred)\n",
        "        f1_value = metrics.f1_score(Y_test, y_pred)\n",
        "\n",
        "        matrix = confusion_matrix(Y_test, y_pred,normalize=\"true\").diagonal()\n",
        "        acc1 = matrix[0]\n",
        "        acc2 = matrix[1]\n",
        "\n",
        "        dict_models[classifier_name] = {'model': classifier, 'train_score': train_score, 'test_score': test_score, 'train_time': t_diff, 'precision':precision_value, 'recall':recall_value, 'f1-value':f1_value, 'acc1':acc1, 'acc2':acc2 }\n",
        "        if verbose:\n",
        "            print(\"trained {c} in {f:.2f} s\".format(c=classifier_name, f=t_diff))\n",
        "    return dict_models\n",
        "\n",
        "\n",
        "\n",
        "def display_dict_models(dict_models, sort_by='test_score'):\n",
        "    cls = [key for key in dict_models.keys()]\n",
        "    test_s = [dict_models[key]['test_score'] for key in cls]\n",
        "    training_s = [dict_models[key]['train_score'] for key in cls]\n",
        "    training_t = [dict_models[key]['train_time'] for key in cls]\n",
        "    prec = [dict_models[key]['precision'] for key in cls]\n",
        "    rec = [dict_models[key]['recall'] for key in cls]\n",
        "    f1 = [dict_models[key]['f1-value'] for key in cls]\n",
        "    acc1 = [dict_models[key]['acc1'] for key in cls]\n",
        "    acc2 = [dict_models[key]['acc2'] for key in cls]\n",
        "\n",
        "\n",
        "    df_ = pd.DataFrame(data=np.zeros(shape=(len(cls),9)), columns = ['classifier', 'train_score', 'test_score', 'train_time','precision','recall','f1-value', 'acc1', 'acc2'])\n",
        "    for ii in range(0,len(cls)):\n",
        "        df_.loc[ii, 'classifier'] = cls[ii]\n",
        "        df_.loc[ii, 'train_score'] = training_s[ii]\n",
        "        df_.loc[ii, 'test_score'] = test_s[ii]\n",
        "        df_.loc[ii, 'train_time'] = training_t[ii]\n",
        "        df_.loc[ii, 'precision'] = prec[ii]\n",
        "        df_.loc[ii, 'recall'] = rec[ii]\n",
        "        df_.loc[ii, 'f1-value'] = f1[ii]\n",
        "        df_.loc[ii, 'acc1'] = acc1[ii]\n",
        "        df_.loc[ii, 'acc2'] = acc2[ii]\n",
        "\n",
        "\n",
        "    display(df_.sort_values(by=sort_by, ascending=False))\n",
        "\n",
        "dict_models = batch_classify(X_train, Y_train, X_test, Y_test, no_classifiers = 10)\n",
        "display_dict_models(dict_models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "TWeKwvSoKMBX",
        "outputId": "a00ddca3-73d9-478f-ce12-1614aeb6e111"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trained Logistic Regression in 0.37 s\n",
            "trained Nearest Neighbors in 0.05 s\n",
            "trained Rbf SVM in 0.06 s\n",
            "trained Decision Tree in 0.17 s\n",
            "trained Random Forest in 4.71 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trained Neural Net in 5.48 s\n",
            "trained Naive Bayes in 0.08 s\n",
            "trained AdaBoost in 2.19 s\n",
            "trained Gradient Boosting Classifier in 23.66 s\n",
            "trained QDA in 0.09 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                     classifier  train_score  test_score  train_time  \\\n",
              "0           Logistic Regression     0.992248        0.76    0.367781   \n",
              "2                       Rbf SVM     1.000000        0.68    0.058235   \n",
              "5                    Neural Net     1.000000        0.68    5.475384   \n",
              "1             Nearest Neighbors     0.775194        0.64    0.052261   \n",
              "9                           QDA     1.000000        0.64    0.087979   \n",
              "4                 Random Forest     1.000000        0.60    4.710731   \n",
              "8  Gradient Boosting Classifier     1.000000        0.56   23.660904   \n",
              "6                   Naive Bayes     0.759690        0.52    0.075558   \n",
              "7                      AdaBoost     1.000000        0.48    2.188275   \n",
              "3                 Decision Tree     1.000000        0.44    0.168142   \n",
              "\n",
              "   precision  recall  f1-value      acc1    acc2  \n",
              "0   0.812500  0.8125  0.812500  0.666667  0.8125  \n",
              "2   0.666667  1.0000  0.800000  0.111111  1.0000  \n",
              "5   0.722222  0.8125  0.764706  0.444444  0.8125  \n",
              "1   0.733333  0.6875  0.709677  0.555556  0.6875  \n",
              "9   0.684211  0.8125  0.742857  0.333333  0.8125  \n",
              "4   0.636364  0.8750  0.736842  0.111111  0.8750  \n",
              "8   0.619048  0.8125  0.702703  0.111111  0.8125  \n",
              "6   0.642857  0.5625  0.600000  0.444444  0.5625  \n",
              "7   0.571429  0.7500  0.648649  0.000000  0.7500  \n",
              "3   0.562500  0.5625  0.562500  0.222222  0.5625  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-897858e2-6c19-4bbe-ae8f-6cb129cd6ae8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classifier</th>\n",
              "      <th>train_score</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_time</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-value</th>\n",
              "      <th>acc1</th>\n",
              "      <th>acc2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.992248</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.367781</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.8125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rbf SVM</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.058235</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Neural Net</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.68</td>\n",
              "      <td>5.475384</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.8125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nearest Neighbors</td>\n",
              "      <td>0.775194</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.052261</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.6875</td>\n",
              "      <td>0.709677</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.6875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>QDA</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.087979</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.742857</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.8125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.60</td>\n",
              "      <td>4.710731</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.8750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.56</td>\n",
              "      <td>23.660904</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.702703</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.8125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.759690</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.075558</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.5625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.48</td>\n",
              "      <td>2.188275</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.648649</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.7500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.168142</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.5625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-897858e2-6c19-4bbe-ae8f-6cb129cd6ae8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-897858e2-6c19-4bbe-ae8f-6cb129cd6ae8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-897858e2-6c19-4bbe-ae8f-6cb129cd6ae8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c2141dce-604a-4560-a91d-bdbc47e5bde5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2141dce-604a-4560-a91d-bdbc47e5bde5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c2141dce-604a-4560-a91d-bdbc47e5bde5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An explanation of each metric displayed in the output DataFrame:\n",
        "\n",
        "1. **Train Score:**\n",
        "   - **Definition:** The accuracy of the model on the training set.\n",
        "   - **Interpretation:** Represents the proportion of correctly classified instances in the training set.\n",
        "\n",
        "2. **Test Score:**\n",
        "   - **Definition:** The accuracy of the model on the test set.\n",
        "   - **Interpretation:** Represents the proportion of correctly classified instances in the test set.\n",
        "\n",
        "3. **Train Time:**\n",
        "   - **Definition:** The time taken to train the model.\n",
        "   - **Interpretation:** Indicates the computational time required for the training phase.\n",
        "\n",
        "4. **Precision:**\n",
        "   - **Definition:** The ability of the classifier not to label as positive a sample that is negative.\n",
        "   - **Interpretation:** High precision indicates a low false-positive rate.\n",
        "\n",
        "5. **Recall:**\n",
        "   - **Definition:** The ability of the classifier to find all the positive samples.\n",
        "   - **Interpretation:** High recall indicates a low false-negative rate.\n",
        "\n",
        "6. **F1-Value:**\n",
        "   - **Definition:** The weighted average of precision and recall.\n",
        "   - **Interpretation:** Provides a balance between precision and recall, especially in imbalanced datasets.\n",
        "\n",
        "7. **Acc1 (Class 1 Accuracy):**\n",
        "   - **Definition:** The accuracy of the model for the first class in a binary classification problem.\n",
        "   - **Interpretation:** Represents the proportion of correctly classified instances for the first class.\n",
        "\n",
        "8. **Acc2 (Class 2 Accuracy):**\n",
        "   - **Definition:** The accuracy of the model for the second class in a binary classification problem.\n",
        "   - **Interpretation:** Represents the proportion of correctly classified instances for the second class.\n",
        "\n",
        "These metrics collectively provide a comprehensive view of the performance of each classifier. It's important to consider the context of the problem being solved and the specific goals when interpreting these metrics. For example, precision and recall are particularly useful in situations where class imbalance is present, and F1-value provides a balanced view of both. Training and test scores give insights into the overall predictive performance of the model on both the training and test datasets."
      ],
      "metadata": {
        "id": "Tfn8BxN7eBWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A brief explanation of each classifier used in the code:\n",
        "\n",
        "1. **Logistic Regression:**\n",
        "   - **Type:** Linear classifier.\n",
        "   - **Use Case:** Binary and multiclass classification.\n",
        "   - **Key Feature:** Utilizes the logistic function to model probabilities.\n",
        "\n",
        "2. **Nearest Neighbors (KNN - K-Nearest Neighbors):**\n",
        "   - **Type:** Instance-based learning.\n",
        "   - **Use Case:** Classification and regression.\n",
        "   - **Key Feature:** Predicts based on the majority class among its k-nearest neighbors.\n",
        "\n",
        "3. **Rbf SVM (Radial Basis Function Support Vector Machine):**\n",
        "   - **Type:** Non-linear classifier.\n",
        "   - **Use Case:** Classification and regression.\n",
        "   - **Key Feature:** Utilizes the radial basis function kernel for non-linear decision boundaries.\n",
        "\n",
        "4. **Decision Tree:**\n",
        "   - **Type:** Tree-based model.\n",
        "   - **Use Case:** Classification and regression.\n",
        "   - **Key Feature:** Makes decisions based on a tree-like graph of decisions.\n",
        "\n",
        "5. **Random Forest:**\n",
        "   - **Type:** Ensemble learning (Bagging).\n",
        "   - **Use Case:** Classification and regression.\n",
        "   - **Key Feature:** Builds multiple decision trees and combines their predictions.\n",
        "\n",
        "6. **Neural Net (Multi-Layer Perceptron - MLP):**\n",
        "   - **Type:** Neural network.\n",
        "   - **Use Case:** Classification and regression.\n",
        "   - **Key Feature:** Consists of multiple layers of interconnected nodes (neurons).\n",
        "\n",
        "7. **Naive Bayes:**\n",
        "   - **Type:** Probabilistic classifier.\n",
        "   - **Use Case:** Text classification and spam filtering.\n",
        "   - **Key Feature:** Applies Bayes' theorem with the assumption of independence between features.\n",
        "\n",
        "8. **AdaBoost:**\n",
        "   - **Type:** Ensemble learning (Boosting).\n",
        "   - **Use Case:** Classification and regression.\n",
        "   - **Key Feature:** Boosts the performance of weak classifiers by assigning more weight to misclassified instances.\n",
        "\n",
        "9. **Gradient Boosting Classifier:**\n",
        "   - **Type:** Ensemble learning (Boosting).\n",
        "   - **Use Case:** Classification and regression.\n",
        "   - **Key Feature:** Builds a series of weak models and corrects errors of the previous models.\n",
        "\n",
        "10. **QDA (Quadratic Discriminant Analysis):**\n",
        "    - **Type:** Discriminant analysis.\n",
        "    - **Use Case:** Classification.\n",
        "    - **Key Feature:** Assumes different covariance matrices for each class.\n",
        "\n",
        "These classifiers cover a range of approaches, from linear models like Logistic Regression to non-linear models like Random Forest and Neural Networks. The choice of classifier depends on the characteristics of the dataset and the nature of the problem being addressed. Experimentation and understanding the strengths and limitations of each classifier help in selecting the most suitable one for a given task."
      ],
      "metadata": {
        "id": "Qe4FNy-Ab9Ox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FAQs for TensorFlow Data Preparation:\n",
        "\n",
        "**1. What is the purpose of this code block?**\n",
        "   - This code block is preparing data for a TensorFlow model that involves both text (tweets) and image features. It shuffles the data, splits it into training and testing sets, and formats the data as TensorFlow tensors.\n",
        "\n",
        "**2. How is the data shuffled and why is shuffling important?**\n",
        "   - The data is shuffled using `data_all.sample(frac=1, random_state=42).values`. Shuffling is important to randomize the order of the data, preventing the model from learning patterns based on the order of the examples.\n",
        "\n",
        "**3. How are the training and testing sets split for both text and image features?**\n",
        "   - The data is split into training and testing sets using row indices. For example, `Y_train` and `X_train_for_tweet` are selected from rows 0 to 128, and `Y_test` and `X_test_for_tweet` are selected from rows 128 to 159. The same approach is applied to image features.\n",
        "\n",
        "**4. What is the purpose of converting labels to TensorFlow tensors (`Y_train_tf` and `Y_test_tf`)?**\n",
        "   - TensorFlow requires data to be in tensor format. Converting labels to TensorFlow tensors (`tf.convert_to_tensor`) is a necessary step for compatibility with TensorFlow models.\n",
        "\n",
        "**5. How are text and image features reshaped for TensorFlow models?**\n",
        "   - Text and image features are reshaped using `tf.reshape` to create three-dimensional tensors with dimensions `[batch_size, 1, feature_dim]`. This format is suitable for feeding into certain types of TensorFlow models.\n",
        "\n",
        "**6. Why is reshaping necessary, and how does it affect model input?**\n",
        "   - Reshaping is necessary to match the expected input shape of the TensorFlow model. Some models, especially those designed for sequential data like text, expect inputs in a specific format. Reshaping ensures compatibility.\n",
        "\n",
        "**7. What does `print(tweet_test_tf)` and `print(image_test_tf)` display?**\n",
        "   - These lines print the TensorFlow tensors for the text and image features of the test set. The printed tensors provide insights into the shape and structure of the data after reshaping.\n",
        "\n",
        "**8. How can I interpret the shape of the printed TensorFlow tensors?**\n",
        "   - The shape indicates the dimensions of the tensor. For example, `[batch_size, 1, 1024]` suggests that there are `batch_size` examples, each with a single feature vector of length 1024.\n",
        "\n",
        "**9. What is the significance of using `random_state=42` in the shuffling process?**\n",
        "   - Setting a random seed (`random_state=42`) ensures reproducibility. If the code is run multiple times, the shuffling process will yield the same random order, making the results reproducible.\n",
        "\n",
        "**10. Why are both text and image features processed separately before being fed into the TensorFlow model?**\n",
        "   - In this code, text and image features are processed separately, and their tensors are created independently. This reflects a model architecture where different types of features are processed through distinct pathways before being combined or concatenated in the model."
      ],
      "metadata": {
        "id": "NJdCsN8K12Lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "data_all[:] = data_all.sample(frac = 1, random_state = 42).values\n",
        "# print(data_all.shape)\n",
        "\n",
        "\n",
        "# 0:8127\n",
        "Y_train = data_all.loc[0:128,3]\n",
        "y_train = np.asarray(Y_train).astype('float32').reshape((-1,1))\n",
        "Y_train_tf = tf.convert_to_tensor(y_train)\n",
        "\n",
        "X_train_for_tweet = data_all.loc[0:128,4:1027]\n",
        "X_train_for_image = data_all.loc[0:128,1028:2051]\n",
        "\n",
        "\n",
        "Y_test = data_all.loc[128:159,3]\n",
        "y_test = np.asarray(Y_test).astype('float32').reshape((-1,1))\n",
        "Y_test_tf = tf.convert_to_tensor(y_test)\n",
        "\n",
        "X_test_for_tweet = data_all.loc[128:159,4:1027]\n",
        "X_test_for_image = data_all.loc[128:159,1028:2051]\n",
        "\n",
        "tweet_test_tf = tf.convert_to_tensor(X_test_for_tweet)\n",
        "image_test_tf = tf.convert_to_tensor(X_test_for_image)\n",
        "\n",
        "tweet_test_tf = tf.reshape(tweet_test_tf, [-1, 1, 1024])\n",
        "image_test_tf = tf.reshape(image_test_tf, [-1, 1, 1024])\n",
        "\n",
        "tweet_train_tf = tf.convert_to_tensor(X_train_for_tweet)\n",
        "image_train_tf = tf.convert_to_tensor(X_train_for_image)\n",
        "\n",
        "tweet_train_tf = tf.reshape(tweet_train_tf, [-1, 1, 1024])\n",
        "image_train_tf = tf.reshape(image_train_tf, [-1, 1, 1024])\n",
        "\n",
        "\n",
        "\n",
        "print(tweet_test_tf)\n",
        "print(image_test_tf)\n",
        "print(Y_test_tf)"
      ],
      "metadata": {
        "id": "qtXIaIFGkDkE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c6d2d1f-c6e2-4f7b-c61e-1e0c63ef7a54"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0.6405898  -0.39440972 -0.30320573 ...  0.15878408 -0.02694301\n",
            "    0.16269414]]\n",
            "\n",
            " [[ 0.5558571  -0.50385505 -0.4134898  ...  0.2026525  -0.06011777\n",
            "    0.17597505]]\n",
            "\n",
            " [[ 0.6198491  -0.51244426 -0.28942192 ...  0.2284957  -0.10170491\n",
            "    0.13566129]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.60938054 -0.46682838 -0.38217747 ...  0.11966185 -0.0428079\n",
            "    0.19083086]]\n",
            "\n",
            " [[ 0.6022376  -0.43535507 -0.43666553 ...  0.17552231 -0.04938225\n",
            "    0.20262015]]\n",
            "\n",
            " [[ 0.6029945  -0.4579286  -0.4637307  ...  0.12119193 -0.0756629\n",
            "    0.24363503]]], shape=(32, 1, 1024), dtype=float64)\n",
            "tf.Tensor(\n",
            "[[[  2.87996088   0.11857334   9.82157054 ...   0.71523022   0.57954354\n",
            "    -0.96521137]]\n",
            "\n",
            " [[  2.96808404   4.11415548  -2.7266678  ...   0.32394929   1.24270041\n",
            "    -0.51138914]]\n",
            "\n",
            " [[  3.74918594  -5.18075239 -19.01096766 ...  -0.08319827  -0.20030917\n",
            "     0.07703108]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[  0.62911457   4.01927538 -10.07962303 ...  -0.3621874   -0.3740202\n",
            "     0.37019341]]\n",
            "\n",
            " [[-22.61264205   2.44197523  -4.03886513 ...  -0.19488943   0.09933688\n",
            "     0.36855277]]\n",
            "\n",
            " [[  3.9462579  -10.96266538   6.11105831 ...  -0.31964118  -0.15194629\n",
            "    -0.30744074]]], shape=(32, 1, 1024), dtype=float64)\n",
            "tf.Tensor(\n",
            "[[1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]], shape=(32, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FAQs for TensorFlow Model Construction:\n",
        "\n",
        "**1. What is the purpose of this code block?**\n",
        "   - This code block defines a neural network model using TensorFlow and Keras. The model takes image and tweet features as inputs, processes them through Bidirectional LSTM layers, and combines them through various mathematical operations.\n",
        "\n",
        "**2. What are the main components of the model architecture?**\n",
        "   - The model consists of two branches: one for processing image features and another for processing tweet features. Each branch includes a Bidirectional LSTM layer, and the outputs are multiplied element-wise. The result undergoes several mathematical operations and is fed into a series of Dense layers.\n",
        "\n",
        "**3. How are image and tweet features processed differently in the model?**\n",
        "   - Image and tweet features are processed separately in two branches with identical Bidirectional LSTM layers. The resulting outputs are multiplied element-wise, and the subsequent operations are applied to the combined features.\n",
        "\n",
        "**4. What is the significance of Bidirectional LSTM layers in each branch?**\n",
        "   - Bidirectional LSTM layers process sequences in both forward and backward directions, capturing context information effectively. This is beneficial for sequential data like text and sequences of image features.\n",
        "\n",
        "**5. What does `tf.math.multiply` do in the model?**\n",
        "   - `tf.math.multiply` performs element-wise multiplication of the outputs of the Bidirectional LSTM layers for image and tweet features. This operation combines the information from both branches.\n",
        "\n",
        "**6. Why are various mathematical operations applied to the combined features?**\n",
        "   - These operations (sign, abs, sqrt, multiply, l2_normalize) are designed to normalize and enhance the representation of the combined features before passing them through the Dense layers. They contribute to feature engineering and can improve the model's ability to capture patterns.\n",
        "\n",
        "**7. What is the purpose of each Dense layer in the model?**\n",
        "   - The Dense layers are responsible for learning non-linear mappings from the combined features to a final output. Each layer gradually reduces the dimensionality of the representation and introduces non-linearity through activation functions.\n",
        "\n",
        "**8. What is the activation function used in the final Dense layer, and why?**\n",
        "   - The final Dense layer uses the sigmoid activation function. This is common in binary classification tasks, where the output represents a probability of belonging to the positive class.\n",
        "\n",
        "**9. How is the overall model architecture constructed?**\n",
        "   - The `tf.keras.Model` is constructed by specifying the inputs (image and tweet features) and the output (result of the final Dense layer). The `summary()` function provides a summary of the model architecture.\n",
        "\n",
        "**10. How can I interpret the summary of the overall model?**\n",
        "   - The summary provides details on the layers, their types, output shapes, and the number of parameters. It helps in understanding the structure of the neural network and the flow of information through it."
      ],
      "metadata": {
        "id": "IwEP2c-U2FTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_image = tf.keras.layers.Input(shape=(1,1024,), name='input_image')\n",
        "input_data_tweet = tf.keras.layers.Input(shape=(1,1024,), name='input_tweet')\n",
        "bilstm_output_image = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, dropout=0.05, recurrent_dropout=0.2))(input_data_image)\n",
        "bilstm_output_tweet = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, dropout=0.05, recurrent_dropout=0.2))(input_data_tweet)\n",
        "multiplied_features = tf.math.multiply(bilstm_output_image,bilstm_output_tweet)\n",
        "avg_pool_2d = tf.keras.layers.AveragePooling2D(pool_size=(3,3), strides=(1,1), padding='same')\n",
        "\n",
        "sign_of_train_features = tf.math.sign(multiplied_features)\n",
        "abs_of_train_features = tf.math.abs(multiplied_features)\n",
        "\n",
        "sqrt_of_train_features = tf.math.sqrt(abs_of_train_features)\n",
        "power_normalized_train_features = tf.math.multiply(sign_of_train_features,sqrt_of_train_features)\n",
        "l2_normalized_features = tf.math.l2_normalize(power_normalized_train_features, axis = 0)\n",
        "features_repr = tf.keras.layers.Dense(516,activation = 'relu')(l2_normalized_features)\n",
        "features_repr1 = tf.keras.layers.Dense(256, activation='relu')(features_repr)\n",
        "features_repr2 = tf.keras.layers.Dense(128, activation='relu')(features_repr1)\n",
        "features_repr3 = tf.keras.layers.Dense(64, activation='relu')(features_repr2)\n",
        "features_repr4 = tf.keras.layers.Dense(16, activation='relu')(features_repr3)\n",
        "features_repr5 = tf.keras.layers.Dense(1, activation='sigmoid')(features_repr4)\n",
        "overall_model = tf.keras.Model([input_data_image,input_data_tweet],features_repr5)\n",
        "overall_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDYCVfR9zoeK",
        "outputId": "790ae91a-08db-4419-9207-ef34930c1ec0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_image (InputLayer)    [(None, 1, 1024)]            0         []                            \n",
            "                                                                                                  \n",
            " input_tweet (InputLayer)    [(None, 1, 1024)]            0         []                            \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirecti  (None, 1024)                 6295552   ['input_image[0][0]']         \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " bidirectional_3 (Bidirecti  (None, 1024)                 6295552   ['input_tweet[0][0]']         \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.multiply_2 (TFOpLa  (None, 1024)                 0         ['bidirectional_2[0][0]',     \n",
            " mbda)                                                               'bidirectional_3[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.abs_1 (TFOpLambda)  (None, 1024)                 0         ['tf.math.multiply_2[0][0]']  \n",
            "                                                                                                  \n",
            " tf.math.sign_1 (TFOpLambda  (None, 1024)                 0         ['tf.math.multiply_2[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.sqrt_1 (TFOpLambda  (None, 1024)                 0         ['tf.math.abs_1[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_3 (TFOpLa  (None, 1024)                 0         ['tf.math.sign_1[0][0]',      \n",
            " mbda)                                                               'tf.math.sqrt_1[0][0]']      \n",
            "                                                                                                  \n",
            " tf.math.l2_normalize_1 (TF  (None, 1024)                 0         ['tf.math.multiply_3[0][0]']  \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 516)                  528900    ['tf.math.l2_normalize_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 256)                  132352    ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 128)                  32896     ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 64)                   8256      ['dense_8[0][0]']             \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 16)                   1040      ['dense_9[0][0]']             \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 1)                    17        ['dense_10[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13294565 (50.71 MB)\n",
            "Trainable params: 13294565 (50.71 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FAQs for Model Compilation and Training:\n",
        "\n",
        "**1. What is the purpose of this code block?**\n",
        "   - This code block compiles and trains the previously defined neural network model using TensorFlow and Keras. The model is compiled with a binary cross-entropy loss function, Adam optimizer with a specific learning rate, and accuracy as the evaluation metric.\n",
        "\n",
        "**2. Why is the model compiled before training?**\n",
        "   - Compilation sets the configuration for the training process, including the choice of optimizer, loss function, and metrics. It prepares the model for training by specifying how it should update its weights during optimization.\n",
        "\n",
        "**3. What loss function is used, and why?**\n",
        "   - The loss function is binary cross-entropy, which is commonly used for binary classification tasks. It measures the difference between predicted probabilities and true labels, guiding the model to improve its predictions.\n",
        "\n",
        "**4. Which optimizer is chosen, and what is its learning rate?**\n",
        "   - The chosen optimizer is Adam, and the learning rate is set to `1e-7` (1.0e-7 or 0.0000001). Adam is an adaptive optimization algorithm, and the learning rate determines the step size during weight updates.\n",
        "\n",
        "**5. Why is accuracy chosen as the evaluation metric?**\n",
        "   - Accuracy is a common metric for classification tasks, representing the proportion of correctly classified instances. It provides a straightforward measure of the model's performance.\n",
        "\n",
        "**6. What does `overall_model.fit` do?**\n",
        "   - The `fit` function trains the model on the provided training data. It iteratively adjusts the model's weights based on the training data to minimize the specified loss function.\n",
        "\n",
        "**7. What are the inputs to the `fit` function?**\n",
        "   - The inputs are the training data (`[image_train_tf, tweet_train_tf]`), corresponding labels (`Y_train_tf`), the number of training epochs, batch size, and verbosity level.\n",
        "\n",
        "**8. How many training epochs are specified, and what does this mean?**\n",
        "   - 200 training epochs are specified. An epoch is one complete pass through the entire training dataset. The model's weights are updated after each epoch, and 200 epochs indicate 200 iterations through the dataset during training.\n",
        "\n",
        "**9. What is the significance of batch size in training?**\n",
        "   - Batch size determines the number of training examples used in each iteration. A smaller batch size can lead to more frequent weight updates, but it may require more iterations. Larger batch sizes can speed up training but may require more memory.\n",
        "\n",
        "**10. Why is verbosity set to 2 in the `fit` function?**\n",
        "   - Verbosity level controls the amount of information printed during training. A verbosity level of 2 prints information for each epoch, providing insights into the training progress.\n",
        "\n",
        "**11. How can I interpret the training output and evaluate model performance?**\n",
        "   - The training output includes information on loss and accuracy for each epoch. After training, you can assess the model's performance on the test set and evaluate metrics such as accuracy, precision, recall, and F1-score."
      ],
      "metadata": {
        "id": "rqFfbkMD2UA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overall_model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-7), metrics=['accuracy'])\n",
        "overall_model.fit([image_train_tf,tweet_train_tf],Y_train_tf,epochs=20, batch_size=32, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx9hrwN5zutw",
        "outputId": "0b24c2f7-4b8a-4253-bb10-2b7e8ae2e754"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "5/5 - 16s - loss: 0.7003 - accuracy: 0.4341 - 16s/epoch - 3s/step\n",
            "Epoch 2/20\n",
            "5/5 - 2s - loss: 0.6949 - accuracy: 0.4419 - 2s/epoch - 340ms/step\n",
            "Epoch 3/20\n",
            "5/5 - 2s - loss: 0.6978 - accuracy: 0.4574 - 2s/epoch - 436ms/step\n",
            "Epoch 4/20\n",
            "5/5 - 1s - loss: 0.6988 - accuracy: 0.4264 - 1s/epoch - 226ms/step\n",
            "Epoch 5/20\n",
            "5/5 - 1s - loss: 0.6970 - accuracy: 0.4806 - 1s/epoch - 228ms/step\n",
            "Epoch 6/20\n",
            "5/5 - 1s - loss: 0.6965 - accuracy: 0.4806 - 1s/epoch - 224ms/step\n",
            "Epoch 7/20\n",
            "5/5 - 1s - loss: 0.6975 - accuracy: 0.4264 - 1s/epoch - 224ms/step\n",
            "Epoch 8/20\n",
            "5/5 - 1s - loss: 0.7016 - accuracy: 0.3876 - 1s/epoch - 224ms/step\n",
            "Epoch 9/20\n",
            "5/5 - 1s - loss: 0.6974 - accuracy: 0.4651 - 1s/epoch - 224ms/step\n",
            "Epoch 10/20\n",
            "5/5 - 1s - loss: 0.6975 - accuracy: 0.4186 - 1s/epoch - 224ms/step\n",
            "Epoch 11/20\n",
            "5/5 - 1s - loss: 0.6968 - accuracy: 0.4729 - 1s/epoch - 223ms/step\n",
            "Epoch 12/20\n",
            "5/5 - 1s - loss: 0.6970 - accuracy: 0.4496 - 1s/epoch - 290ms/step\n",
            "Epoch 13/20\n",
            "5/5 - 3s - loss: 0.6991 - accuracy: 0.4496 - 3s/epoch - 521ms/step\n",
            "Epoch 14/20\n",
            "5/5 - 2s - loss: 0.6987 - accuracy: 0.4419 - 2s/epoch - 413ms/step\n",
            "Epoch 15/20\n",
            "5/5 - 1s - loss: 0.6987 - accuracy: 0.4341 - 1s/epoch - 244ms/step\n",
            "Epoch 16/20\n",
            "5/5 - 1s - loss: 0.6976 - accuracy: 0.4419 - 1s/epoch - 218ms/step\n",
            "Epoch 17/20\n",
            "5/5 - 1s - loss: 0.6986 - accuracy: 0.3798 - 1s/epoch - 226ms/step\n",
            "Epoch 18/20\n",
            "5/5 - 1s - loss: 0.7009 - accuracy: 0.3798 - 1s/epoch - 218ms/step\n",
            "Epoch 19/20\n",
            "5/5 - 1s - loss: 0.6991 - accuracy: 0.4341 - 1s/epoch - 229ms/step\n",
            "Epoch 20/20\n",
            "5/5 - 1s - loss: 0.6981 - accuracy: 0.4806 - 1s/epoch - 220ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b5957e15bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FAQs for Model Evaluation:\n",
        "\n",
        "**1. What is the purpose of this code block?**\n",
        "   - This code block evaluates the performance of the trained neural network model on the test set. It uses the `evaluate` function to compute the test loss and accuracy.\n",
        "\n",
        "**2. Why is the model being evaluated on the test set?**\n",
        "   - The test set serves as a separate dataset not seen by the model during training. Evaluating on the test set provides an unbiased assessment of the model's generalization performance.\n",
        "\n",
        "**3. What are the inputs to the `evaluate` function?**\n",
        "   - The inputs include the test data (`[image_test_tf, tweet_test_tf]`), corresponding labels (`Y_test_tf`), batch size for evaluation, and verbosity level.\n",
        "\n",
        "**4. What information does `results` contain?**\n",
        "   - `results` contains the computed test loss and accuracy. These metrics provide insights into how well the model performs on unseen data.\n",
        "\n",
        "**5. How is test loss interpreted?**\n",
        "   - Test loss represents the value of the chosen loss function on the test set. It indicates how well the predicted probabilities align with the true labels.\n",
        "\n",
        "**6. How is test accuracy interpreted?**\n",
        "   - Test accuracy is the proportion of correctly classified instances in the test set. It provides a high-level measure of the model's performance.\n",
        "\n",
        "**7. Why is batch size specified during evaluation?**\n",
        "   - Batch size determines the number of examples processed in each evaluation iteration. A larger batch size can speed up evaluation but may require more memory. It doesn't affect the final evaluation results.\n",
        "\n",
        "**8. What does `verbose=2` mean in the `evaluate` function?**\n",
        "   - Verbosity level controls the amount of information printed during evaluation. A verbosity level of 2 prints information about the evaluation process, including the test loss and accuracy.\n",
        "\n",
        "**9. How can I interpret the printed test loss and accuracy?**\n",
        "   - The printed output provides the computed test loss and accuracy. A lower test loss and a higher test accuracy indicate better model performance on the test set.\n",
        "\n",
        "**10. What is the significance of printing test loss and accuracy?**\n",
        "   - Printing these metrics allows you to assess how well the model generalizes to new, unseen data. It is a critical step in understanding the model's effectiveness in real-world scenarios."
      ],
      "metadata": {
        "id": "fss7TUOw2_6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = overall_model.evaluate([image_test_tf,tweet_test_tf], Y_test_tf, batch_size=64,verbose = 2)\n",
        "print('test loss, test acc:', results)"
      ],
      "metadata": {
        "id": "qRoYaqxr2aQ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421eef3f-efd4-4378-898c-256b9bcc9204"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 3s - loss: 0.6898 - accuracy: 0.5000 - 3s/epoch - 3s/step\n",
            "test loss, test acc: [0.6897960305213928, 0.5]\n"
          ]
        }
      ]
    }
  ]
}